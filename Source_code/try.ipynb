{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "f = open(\"infarcts.csv\", \"r\")\n",
    "naming_dict = {}\n",
    "fileContents = f.read()\n",
    "list_of_disease = []\n",
    "fileContents = fileContents.split('\\n')\n",
    "\n",
    "\n",
    "fileContents.pop(34)\n",
    "\n",
    "for i in range(1,len(fileContents)-1):\n",
    "    fileContents[i] = fileContents[i].split(',')\n",
    "    naming_dict[\"DWI\"+str(i)] = fileContents[i][5]\n",
    "    list_of_disease.append(fileContents[i][5])\n",
    "naming_dict['DWI33'] = 'Lacunar infact in posterior limb of left internal capsule'\n",
    "list_of_disease[32] = 'Lacunar infact in posterior limb of left internal capsule'\n",
    "# print(naming_dict)\n",
    "\n",
    "naming_dict['DWI3'] = 'Right parietal lobe'\n",
    "naming_dict['DWI12'] = 'Bilateral cerebellar hemispheres'\n",
    "naming_dict['DWI16'] = 'Left parietal lobe'\n",
    "naming_dict['DWI35'] = 'Right corona radiata'\n",
    "naming_dict['DWI40'] = 'Bilateral occipital lobes'\n",
    "naming_dict['DWI44'] = 'Right parietal lobe'\n",
    "\n",
    "list_of_disease[2] = 'Right parietal lobe'\n",
    "list_of_disease[11] ='Bilateral cerebellar hemispheres'\n",
    "list_of_disease[15] = 'Left parietal lobe'\n",
    "list_of_disease[32] = 'Lacunar infarct in posterior limb of left internal capsule'\n",
    "list_of_disease[34] =  'Right corona radiata'\n",
    "list_of_disease[39] = 'Bilateral occipital lobes'\n",
    "list_of_disease[43] = 'Right parietal lobe'\n",
    "\n",
    "list_of_dict = list(v for v in naming_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.mkdir('C:/Users/Dell/Desktop/DL/TRAIN_DATA')\n",
    "    os.mkdir('C:/Users/Dell/Desktop/DL/TEST_DATA')\n",
    "except:\n",
    "    pass\n",
    "src = 'C:/Users/Dell/Desktop/DL/CLEANED_DATA/'\n",
    "dst = 'C:/Users/Dell/Desktop/DL/TRAIN_DATA/'\n",
    "dst2 = 'C:/Users/Dell/Desktop/DL/TEST_DATA/'\n",
    "ckeck = False\n",
    "list_unique = list(set(list_of_disease))\n",
    "for i in list_unique:\n",
    "    check = True\n",
    "    for j in range (1,51):\n",
    "        try:\n",
    "            if(check):\n",
    "                shutil.copy(src = src+str(i)+\"/DWI\"+str(j)+\".jpg\",dst=dst+\"DWI\"+str(j)+\".jpg\")\n",
    "                check = False  \n",
    "            else :\n",
    "                shutil.copy(src = src+str(i)+\"/DWI\"+str(j)+\".jpg\",dst=dst2+\"DWI\"+str(j)+\".jpg\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "                                \n",
    "        \n",
    "\n",
    "list_of_dir = []\n",
    "for x in os.listdir(src):\n",
    "    list_of_dir.append(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/Dell/Desktop/DL/TRAIN_DATA\"\n",
    "training_data = []\n",
    "i =1\n",
    "size = 100\n",
    "for img in os.listdir(path):\n",
    "    try:\n",
    "        x=img.replace(\".jpg\",\"\")\n",
    "        image = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image,(size,size))\n",
    "        training_data.append([image,naming_dict[x]])\n",
    "        i=i+1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "path = \"C:/Users/Dell/Desktop/DL/TEST_DATA\"\n",
    "test_data = []\n",
    "i =1\n",
    "\n",
    "\n",
    "for img in os.listdir(path):\n",
    "    try:\n",
    "        x=img.replace(\".jpg\",\"\")\n",
    "        image = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image,(size,size))\n",
    "        test_data.append([image,naming_dict[x]])\n",
    "        i=i+1\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from numpy import expand_dims\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for images,label in training_data:\n",
    "    X.append(images)\n",
    "    Y.append(label)\n",
    "    \n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for images,label in test_data:\n",
    "    X_test.append(images)\n",
    "    Y_test.append(label) \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460, 1, 100, 100, 1)\n",
      "(460,)\n"
     ]
    }
   ],
   "source": [
    "X_aug = []\n",
    "Y_aug = []\n",
    "X_aug_test = []\n",
    "Y_aug_test = []\n",
    "\n",
    "\n",
    "#Data augmentation function with paratmeters\n",
    "datagen = ImageDataGenerator( width_shift_range=0.05, \n",
    "                                 height_shift_range=0.05,\n",
    "                                 zoom_range=0.1,\n",
    "                                 shear_range=0.1,\n",
    "                                 rescale=1./255)\n",
    "\n",
    "#Data Augmentation Implementation\n",
    "for images,label in training_data:\n",
    "    data = img_to_array(images)\n",
    "    samples = expand_dims(data,0)\n",
    "    it = datagen.flow(samples, batch_size=1,save_to_dir=\"./aug_images\", save_prefix=label, save_format=\"jpg\")\n",
    "    for i in range(10):\n",
    "        temp = it.next()\n",
    "        X_aug.append(temp)\n",
    "        Y_aug.append(label)\n",
    "\n",
    "print(np.shape(X_aug))\n",
    "print(np.shape(Y_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 100, 100, 1)\n",
      "(46,)\n",
      "(460, 100, 100, 1)\n",
      "(460,)\n",
      "(4, 100, 100, 1)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "npX = np.array(X).reshape(-1,size,size,1)\n",
    "npY = np.array(Y).reshape(-1)\n",
    "npX_aug = np.array(X_aug).reshape(-1,size,size,1)\n",
    "npY_aug = np.array(Y_aug).reshape(-1)\n",
    "\n",
    "print(np.shape(npX))\n",
    "print(np.shape(npY)) \n",
    "print(np.shape(npX_aug))\n",
    "print(np.shape(npY_aug)) \n",
    "\n",
    "npX_test = np.array(X_test).reshape(-1,size,size,1)\n",
    "npY_test = np.array(Y_test).reshape(-1)\n",
    "npX_aug_test = np.array(X_aug_test).reshape(-1,size,size,1)\n",
    "npY_aug_test = np.array(Y_aug_test).reshape(-1)\n",
    "\n",
    "print(np.shape(npX_test))\n",
    "print(np.shape(npY_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 98, 98, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 49, 49, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 49, 49, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 47, 47, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                2708520   \n",
      "=================================================================\n",
      "Total params: 2,783,016\n",
      "Trainable params: 2,783,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D((64),(3,3), input_shape = (size,size,1), activation = 'relu' ))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D((128),(3,3), activation = 'relu' ))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(Conv2D((256),(3,3), activation = 'relu' ))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(128 , activation = 'relu' ))\n",
    "# model.add(Dense(64 , activation = 'relu' ))\n",
    "model.add(Dense(40 , activation = 'softmax' ))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed label is : [39 36 28  0 31 35 13 20 14 38  3 24  8 16 33 17  2 19 12 27  9 36  5  4\n",
      "  0 28 18 25  6  7 10  2  1 23 34 36 11 30 21 15 26 22 29 37 32 20]\n",
      "(460, 40)\n",
      "(4, 40)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "transformed_label = encoder.fit_transform(npY)\n",
    "transformed_label2 = encoder.fit_transform(npY_aug)\n",
    "print(\"Transformed label is :\",transformed_label)\n",
    "\n",
    "y_test_binary = []\n",
    "y_binary = to_categorical(transformed_label)\n",
    "y_binary2 = to_categorical(transformed_label2)\n",
    "for i in Y_test:\n",
    "    y_test_binary.append(y_binary[np.where(npY==i)[0][0]])\n",
    "    \n",
    "y_test_binary = np.array(y_test_binary)\n",
    "\n",
    "print(y_binary2.shape)  \n",
    "print(y_test_binary.shape)\n",
    "\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(npX_aug,y_binary2,test_size=0.1,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 414 samples, validate on 46 samples\n",
      "Epoch 1/10\n",
      "414/414 [==============================] - 22s 54ms/sample - loss: 3.5585 - acc: 0.0459 - val_loss: 3.1601 - val_acc: 0.1304\n",
      "Epoch 2/10\n",
      "414/414 [==============================] - 22s 53ms/sample - loss: 2.9495 - acc: 0.2053 - val_loss: 2.4254 - val_acc: 0.3261\n",
      "Epoch 3/10\n",
      "414/414 [==============================] - 21s 51ms/sample - loss: 1.5326 - acc: 0.6039 - val_loss: 1.3251 - val_acc: 0.6522\n",
      "Epoch 4/10\n",
      "414/414 [==============================] - 21s 51ms/sample - loss: 0.4125 - acc: 0.8913 - val_loss: 0.8012 - val_acc: 0.7174\n",
      "Epoch 5/10\n",
      "414/414 [==============================] - 22s 52ms/sample - loss: 0.0749 - acc: 0.9758 - val_loss: 0.6015 - val_acc: 0.8043\n",
      "Epoch 6/10\n",
      "414/414 [==============================] - 21s 52ms/sample - loss: 0.0169 - acc: 0.9952 - val_loss: 0.4689 - val_acc: 0.8478\n",
      "Epoch 7/10\n",
      "414/414 [==============================] - 22s 53ms/sample - loss: 0.0160 - acc: 0.9976 - val_loss: 0.5151 - val_acc: 0.8478\n",
      "Epoch 8/10\n",
      "414/414 [==============================] - 22s 52ms/sample - loss: 0.0033 - acc: 1.0000 - val_loss: 0.5413 - val_acc: 0.8043\n",
      "Epoch 9/10\n",
      "414/414 [==============================] - 21s 52ms/sample - loss: 0.0158 - acc: 0.9952 - val_loss: 0.5192 - val_acc: 0.8043\n",
      "Epoch 10/10\n",
      "414/414 [==============================] - 23s 54ms/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.4602 - val_acc: 0.8043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24f01376848>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = \"adam\", loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model.fit(x_train, y_train ,validation_data=(x_validate,y_validate), batch_size = 1, epochs = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Prediction of  Splenium of the corpus callosum  is  Pontine infarct on the right\n",
      "Prediction of  Right parietal lobe  is  Right parietal lobe\n",
      "Prediction of  Right corona radiata  is  Left centrum semi ovale and right parietal lobe\n",
      "Prediction of  Bilateral cerebellar hemispheres  is  Right cerebellar hemisphere\n",
      "Prediction of  Right fronto-parieto-temporo- occipital lobes  is  Right frontal lobe\n",
      "Prediction of  Right occipital lobe  is  Right temporal lobe\n",
      "Prediction of  Left frontal lobe  is  Right ganglio-capsular region\n",
      "Prediction of  Left parietal lobe  is  Left parietal lobe\n",
      "Prediction of  Left frontal lobe in precentral gyral location  is  Right corona radiata\n",
      "Prediction of  Right thalamus  is  Right corona radiata\n",
      "Prediction of  Brainstem  is  Bilateral cerebellar hemispheres\n",
      "Prediction of  Pontine infarct on the right  is  Right fronto-parieto-temporo- occipital lobes\n",
      "Prediction of  Lacunar infarct in right putamen  is  Right occipital lobe\n",
      "Prediction of  Left fronto-temporo-parietal region  is  Left frontal lobe\n",
      "Prediction of  Right insula  is  Left parietal lobe\n",
      "Prediction of  Left insula  is  Left parietal lobe\n",
      "Prediction of  Bilateral occipital lobes  is  Right thalamus\n",
      "Prediction of  Left occipital lobe  is  Right parietal lobe\n",
      "Prediction of  Left cerebellar lacunar infarcts  is  Lacunar infarct in right putamen\n",
      "Prediction of  Right cerebellar hemisphere infarct  is  Left fronto-temporo-parietal region\n",
      "Prediction of  Lacunar infarcts in left corona radiata  is  Right insula\n",
      "Prediction of  Right parietal lobe  is  Right corona radiata\n",
      "Prediction of  Lacunar infarct in dorsal aspect of pons  is  Bilateral occipital lobes\n",
      "Prediction of  Lacunar infact in posterior limb of left internal capsule  is  Bilateral occipital lobes\n",
      "Prediction of  Bilateral cerebellar hemispheres  is  Right parietal lobe\n",
      "Prediction of  Right corona radiata  is  Left centrum semi ovale and right parietal lobe\n",
      "Prediction of  Left occipital and temporal lobes  is  Right cerebellar hemisphere infarct\n",
      "Prediction of  Right anterior thalamic infarct  is  Right corona radiata\n",
      "Prediction of  Lacunar infarct in medulla oblongata on the left  is  Left parietal lobe\n",
      "Prediction of  Lacunar infarct in pons on the left  is  Lacunar infarct in dorsal aspect of pons\n",
      "Prediction of  Left centrum semi ovale and right parietal lobe  is  Right corona radiata\n",
      "Prediction of  Bilateral occipital lobes  is  Right thalamus\n",
      "Prediction of  Bilateral frontal lobes  is  Bilateral occipital lobes\n",
      "Prediction of  Mid brain on right side  is  Right corona radiata\n",
      "Prediction of  Right lentiform nucleus  is  Right insula\n",
      "Prediction of  Right parietal lobe  is  Right parietal lobe\n",
      "Prediction of  Left cerebellar hemisphere  is  Lacunar infarct in medulla oblongata on the left\n",
      "Prediction of  Right fronto-parietal lobe  is  Lacunar infarct in pons on the left\n",
      "Prediction of  Left thalamic lacunar infarct  is  Bilateral occipital lobes\n",
      "Prediction of  Left fronto-parietal lobe  is  Left centrum semi ovale and right parietal lobe\n",
      "Prediction of  Right cerebellar hemisphere  is  Mid brain on right side\n",
      "Prediction of  Medial part of right frontal and parietal lobes  is  Right lentiform nucleus\n",
      "Prediction of  Right frontal lobe  is  Right parietal lobe\n",
      "Prediction of  Right temporal lobe  is  Left cerebellar hemisphere\n",
      "Prediction of  Right ganglio-capsular region  is  Right fronto-parietal lobe\n",
      "Prediction of  Left parietal lobe  is  Right corona radiata\n",
      "Accuracy =  76.08695652173914\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(npX)\n",
    "print(predictions)\n",
    "acc = 0\n",
    "for i in range(46):\n",
    "    ans = np.argmax(predictions[i])\n",
    "    print(\"Prediction of \",Y[i],\" is \",list_of_dict[int(np.where(transformed_label==ans)[0][0])+1])\n",
    "    if(ans==transformed_label[i]):\n",
    "        acc=acc+1\n",
    "per_acc = (acc/46)*100\n",
    "print(\"Accuracy = \",per_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 2.1219968e-30 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "Right frontal lobe (is matched with) Right anterior thalamic infarct\n",
      "Left parietal lobe (is matched with) Left parietal lobe\n",
      "Right corona radiata (is matched with) Pontine infarct on the right\n",
      "Right temporal lobe (is matched with) Pontine infarct on the right\n",
      "Accuracy =  25.0\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(npX_test)\n",
    "print(predictions)\n",
    "acc = 0\n",
    "for i in range(4):\n",
    "    ans = np.argmax(predictions[i])\n",
    "\n",
    "    print(Y_test[i],\"(is matched with)\",list_of_disease[int(np.where(transformed_label==ans)[0][0])-1])\n",
    "    if(ans==transformed_label[i]):\n",
    "        acc=acc+1\n",
    "per_acc = (acc/4)*100\n",
    "print(\"Accuracy = \",per_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fname = \"./model/try.h5\"\n",
    "model.save(model_fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "['conv2d_2_input'] ['dense_1/Softmax']\n",
      "WARNING:tensorflow:From <ipython-input-19-64af4ad0f96f>:13: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.remove_training_nodes`\n",
      "WARNING:tensorflow:From <ipython-input-19-64af4ad0f96f>:14: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 6 variables.\n",
      "INFO:tensorflow:Converted 6 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_io\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# Clear any previous session.\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "save_pb_dir = './model'\n",
    "model_fname = './model/try.h5'\n",
    "def freeze_graph(graph, session, output, save_pb_dir='.', save_pb_name='frozen_model.pb', save_pb_as_text=False):\n",
    "    with graph.as_default():\n",
    "        graphdef_inf = tf.graph_util.remove_training_nodes(graph.as_graph_def())\n",
    "        graphdef_frozen = tf.graph_util.convert_variables_to_constants(session, graphdef_inf, output)\n",
    "        graph_io.write_graph(graphdef_frozen, save_pb_dir, save_pb_name, as_text=save_pb_as_text)\n",
    "        return graphdef_frozen\n",
    "\n",
    "# This line must be executed before loading Keras model.\n",
    "tf.keras.backend.set_learning_phase(0) \n",
    "\n",
    "model = load_model(model_fname)\n",
    "\n",
    "session = tf.keras.backend.get_session()\n",
    "\n",
    "INPUT_NODE = [t.op.name for t in model.inputs]\n",
    "OUTPUT_NODE = [t.op.name for t in model.outputs]\n",
    "print(INPUT_NODE, OUTPUT_NODE)\n",
    "frozen_graph = freeze_graph(session.graph, session, [out.op.name for out in model.outputs], save_pb_dir=save_pb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \tC:\\Users\\Dell\\Desktop\\DL\\./model/frozen_model.pb\n",
      "\t- Path for generated IR: \tC:\\Users\\Dell\\Desktop\\DL\\./model\n",
      "\t- IR output name: \tfrozen_model\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \t[1,100,100,1]\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
      "\t- Operations to offload: \tNone\n",
      "\t- Patterns to offload: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "Model Optimizer version: \t2019.3.0-408-gac8584cb7\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: C:\\Users\\Dell\\Desktop\\DL\\./model\\frozen_model.xml\n",
      "[ SUCCESS ] BIN file: C:\\Users\\Dell\\Desktop\\DL\\./model\\frozen_model.bin\n",
      "[ SUCCESS ] Total execution time: 12.59 seconds. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-01 10:38:57.178376: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_100.dll'; dlerror: cudart64_100.dll not found\n",
      "2020-05-01 10:38:57.178625: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "is_win = 'windows' in platform.platform().lower()\n",
    "\n",
    "# OpenVINO 2019\n",
    "if is_win:\n",
    "    mo_tf_path = '\"C:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo_tf.py\"'\n",
    "else:\n",
    "    # mo_tf.py path in Linux\n",
    "    mo_tf_path = '/opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py'\n",
    "\n",
    "pb_file = './model/frozen_model.pb'\n",
    "output_dir = './model'\n",
    "img_height = 100\n",
    "input_shape = [1,img_height,img_height,1]\n",
    "input_shape_str = str(input_shape).replace(' ','')\n",
    "input_shape_str\n",
    "# print(input_shape_str)\n",
    "\n",
    "!python {mo_tf_path} --input_model {pb_file} --output_dir {output_dir} --input_shape {input_shape_str} --data_type FP32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
